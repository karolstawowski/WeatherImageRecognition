{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ax_L5G2pkoG5"
   },
   "source": [
    "# Weather image recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCp6b8S8koG_",
    "outputId": "3835c956-1909-492f-8673-8086208bb74d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5vTuC8lMWrZU"
   },
   "outputs": [],
   "source": [
    "local_folder = './dataset'\n",
    "train_dir = local_folder + '/train'\n",
    "valid_dir = local_folder + '/valid'\n",
    "test_dir = local_folder + '/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgVckJHGWrZU",
    "outputId": "029b99e0-3f3b-4b9c-e6f6-55cc67a43bf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5484 images belonging to 11 classes.\n",
      "Found 696 images belonging to 11 classes.\n",
      "Found 682 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255, horizontal_flip=True, vertical_flip=True, rotation_range=10)\n",
    "\n",
    "target_image_size = (256, 256)\n",
    "\n",
    "train_dataset = datagen.flow_from_directory(train_dir,\n",
    "                                                  target_size = target_image_size,\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  class_mode=\"categorical\")\n",
    "\n",
    "test_dataset = datagen.flow_from_directory(test_dir,\n",
    "                                                target_size = target_image_size,\n",
    "                                                batch_size = batch_size,\n",
    "                                                class_mode=\"categorical\")\n",
    "\n",
    "valid_dataset = datagen.flow_from_directory(valid_dir,\n",
    "                                                  target_size = target_image_size,\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of images each dataset contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DSSp-TiWrZV"
   },
   "outputs": [],
   "source": [
    "num_train_examples = 5484\n",
    "num_test_examples = 696\n",
    "num_valid_examples = 682"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1IBPESAXpIB"
   },
   "source": [
    "## Convolutional Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Slz9YOwykoHK"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape = (256, 256, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(strides = 2))\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(strides = 2))\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(7, 7, 128)))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(11, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tP9ZjGP3koHK"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "id": "m0hFtQdrkoHK",
    "outputId": "8d1da5e7-9b98-412f-91e8-e9a6535a0624",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28cWfG5P6KnZ",
    "outputId": "64a9ca97-1d9b-4dd0-aefb-85ca0f54b864",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 128)     36992     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 524288)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               67108992  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 11)                1419      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,148,299\n",
      "Trainable params: 67,148,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAUlI9wckoHK"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qda85maCzAOx",
    "outputId": "0c3a6ff4-79c4-4260-9b84-1516d7ad1868",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "172/172 [==============================] - 75s 437ms/step - loss: 0.7141 - acc: 0.7613 - val_loss: 1.0744 - val_acc: 0.6540\n",
      "Epoch 2/8\n",
      "172/172 [==============================] - 75s 434ms/step - loss: 0.6653 - acc: 0.7774 - val_loss: 1.0324 - val_acc: 0.6760\n",
      "Epoch 3/8\n",
      "172/172 [==============================] - 75s 435ms/step - loss: 0.6025 - acc: 0.7965 - val_loss: 1.0682 - val_acc: 0.6848\n",
      "Epoch 4/8\n",
      "172/172 [==============================] - 76s 439ms/step - loss: 0.5844 - acc: 0.7989 - val_loss: 0.9445 - val_acc: 0.6994\n",
      "Epoch 5/8\n",
      "172/172 [==============================] - 75s 437ms/step - loss: 0.5413 - acc: 0.8208 - val_loss: 0.9730 - val_acc: 0.7053\n",
      "Epoch 6/8\n",
      "172/172 [==============================] - 75s 434ms/step - loss: 0.5279 - acc: 0.8187 - val_loss: 1.0186 - val_acc: 0.7009\n",
      "Epoch 7/8\n",
      "172/172 [==============================] - 74s 432ms/step - loss: 0.4926 - acc: 0.8350 - val_loss: 1.0169 - val_acc: 0.6716\n",
      "Epoch 8/8\n",
      "172/172 [==============================] - 75s 435ms/step - loss: 0.4841 - acc: 0.8363 - val_loss: 1.0542 - val_acc: 0.6848\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=epochs, validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsHu4ZjzkoHL"
   },
   "source": [
    "## Train and test datasets accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yXu8VPbxkoHL",
    "outputId": "e33988c5-7012-4802-9292-ca6c2be5a6b6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 67s 389ms/step - loss: 0.4749 - acc: 0.8472\n",
      "22/22 [==============================] - 9s 413ms/step - loss: 1.0744 - acc: 0.6940\n",
      "Train accuracy: 84.72%\n",
      "Test accuracy: 69.40%\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(train_dataset, steps=math.ceil(num_train_examples / batch_size))\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples / batch_size))\n",
    "\n",
    "print('Train accuracy: {:.2f}%'.format(100*train_accuracy))\n",
    "print('Test accuracy: {:.2f}%'.format(100*test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('gputest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe4e2fe76e34914d71d98e05b7ba1ae6694b052bab24cbf372ac0a5b2bf0c0eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
